{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sélections de variables\n",
    "\n",
    "$$\n",
    "\\ln\\mathcal{L}(\\mu,\\sigma^2)\n",
    "    \\, = \\, -\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln\\sigma^2 - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (x_i-\\mu)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "% matplotlib inline\n",
    "np.set_printoptions(precision=2,linewidth=500,suppress=True)\n",
    "\n",
    "\"\"\"pour que les dataFrame ne soient pas trop coupées dans la console\"\"\"\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>TotalIncome</th>\n",
       "      <th>LoanAmount/TotalIncome</th>\n",
       "      <th>Graduate&amp;Self_Employed</th>\n",
       "      <th>TotalIncome_log</th>\n",
       "      <th>PA_Rural</th>\n",
       "      <th>PA_Urban</th>\n",
       "      <th>Dependents_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5849</td>\n",
       "      <td>146.412162</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5849.0</td>\n",
       "      <td>0.025032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.674026</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4583</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6091.0</td>\n",
       "      <td>0.021015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.714568</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.006368</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2583</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4941.0</td>\n",
       "      <td>0.024287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.505323</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.699515</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Married  Education  Self_Employed  ApplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  Loan_Status  TotalIncome  LoanAmount/TotalIncome  Graduate&Self_Employed  TotalIncome_log  PA_Rural  PA_Urban  Dependents_num\n",
       "0     0.0      0.0        1.0            0.0             5849  146.412162             360.0             1.0          1.0       5849.0                0.025032                     0.0         8.674026         0         1             0.0\n",
       "1     0.0      1.0        1.0            0.0             4583  128.000000             360.0             1.0          1.0       6091.0                0.021015                     0.0         8.714568         1         0             1.0\n",
       "2     0.0      1.0        1.0            1.0             3000   66.000000             360.0             1.0          1.0       3000.0                0.022000                     1.0         8.006368         0         1             0.0\n",
       "3     0.0      1.0        0.0            0.0             2583  120.000000             360.0             1.0          1.0       4941.0                0.024287                     0.0         8.505323         0         1             0.0\n",
       "4     0.0      0.0        1.0            0.0             6000  141.000000             360.0             1.0          1.0       6000.0                0.023500                     0.0         8.699515         0         1             0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/loan_data_preprossed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On effectuer une classification en utilisant la cross_validation. C'est un procédé très utile quand on n'a pas\n",
    " beaucoup de données (600 lignes, c'est pas énorme). Les données sont séparées en k-parties (=fold).\n",
    "\n",
    "* la partie 1 sert de test, les parties 2,3,...,n servent de train\n",
    "*  puis la partie 2 sert de test, les autres de train\n",
    "*  etc.\n",
    "\n",
    "On fait ensuite la moyenne de tous les scores obtenu sur les tests. Attention, les k-parties doivent respecter la proportion d'élément de chaque classe.\n",
    "\n",
    "\n",
    "Par ailleurs, quand on a des variable numériques pouvant prendre de grande valeur, il vaut mieux les centrée-réduire :\n",
    "  sinon, la plupart de algorithmes  de classification et de regression échouent (exception notoire: le modèle linéaire).\n",
    "  \n",
    " Mais attention  : si l'on a des valeurs extrême, le fait de centrer réduire peut décaler les moyennes et écraser les valeurs. Avant de centrer réduire, il faut s'occuper des valeurs extrêmes. Nous l'avons déjà fait lors de l'exploration des données (on a passé les incomes au logarithme). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender' 'Married' 'Education' 'Self_Employed' 'ApplicantIncome' 'LoanAmount' 'Loan_Amount_Term' 'Credit_History' 'TotalIncome' 'LoanAmount/TotalIncome' 'Graduate&Self_Employed' 'TotalIncome_log' 'PA_Rural' 'PA_Urban' 'Dependents_num']\n"
     ]
    }
   ],
   "source": [
    "df_input=df.drop(columns=\"Loan_Status\")\n",
    "all_features=df_input.columns.values\n",
    "X = df_input.values\n",
    "Y = df[\"Loan_Status\"].values\n",
    "print(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'aic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b399542af21d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_logistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mhat_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"proba-error:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhat_Y_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'aic'"
     ]
    }
   ],
   "source": [
    "\"la méthode de regression logistique de sklearn : Attention, par défaut elle a une très faible pénalisation L2.\"\n",
    "model_logistic = linear_model.LogisticRegression(class_weight ='balanced')\n",
    "model_logistic.fit(X, Y)\n",
    "\n",
    "hat_Y=model_logistic.predict(X)\n",
    "hat_Y_proba=model_logistic.predict_proba(X)\n",
    "\n",
    "\n",
    "print(model_logistic.aic)\n",
    "print(\"accuracy:\",np.mean(Y==hat_Y))\n",
    "print(\"proba-error:\",(np.abs(Y-hat_Y_proba[:,1])).mean())\n",
    "print(\"cross-entropy:\",-((Y*np.log(hat_Y_proba[:,1])).mean()))\n",
    "print(\"decision_function:\",model_logistic.decision_function(X).mean())\n",
    "nb=20\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(Y[:nb],\"o\",label=\"Y\")\n",
    "plt.plot(hat_Y[:nb],\"r+\",label=r\"$\\hat Y$\")\n",
    "plt.plot(hat_Y_proba[:nb,1],\".\",label=\"proba[1]\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_VC(model,inputNames,centerReduce=True):\n",
    "    \n",
    "    X = df.loc[:, inputNames].values\n",
    "    if centerReduce: X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "    skf = model_selection.StratifiedKFold(n_splits=8)\n",
    "    nb=0\n",
    "    mean=0\n",
    "    \"\"\" Question: comment fonctionne StratifiedKFold ?  Pourquoi a-t-elle besoin de Y ? \"\"\"\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        nb+=1\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        mean+=model.decision_function(X_test).mean()\n",
    "        \n",
    "\n",
    "    mean/=nb\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6657568438420941\n"
     ]
    }
   ],
   "source": [
    "score=classification_VC(model_logistic,['LoanAmount','ApplicantIncome'])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TotalIncome', 1.1935974726176344),\n",
       " ('LoanAmount/TotalIncome', 0.8113658202999158),\n",
       " ('TotalIncome_log', 0.6569322553954499),\n",
       " ('ApplicantIncome', 0.6360949206245533),\n",
       " ('LoanAmount', 0.047130859991611124),\n",
       " ('Education', 0.03173205849785099),\n",
       " ('Credit_History', 0.02587240307387683),\n",
       " ('Gender', 0.014967342267009007),\n",
       " ('Graduate&Self_Employed', 0.007297062928144088),\n",
       " ('Loan_Amount_Term', 0.00701488786352611),\n",
       " ('Married', 0.006116125043698648),\n",
       " ('Self_Employed', 0.005690996433402067),\n",
       " ('Dependents_num', 0.0001124217492774911),\n",
       " ('PA_Rural', -0.00029900456710627043),\n",
       " ('PA_Urban', -0.002826133144155191)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" regardons quelle est la meilleur feature\"\"\"\n",
    "feature_score=[]\n",
    "for feature in all_features:\n",
    "    score=classification_VC(model_logistic,[feature])\n",
    "    feature_score.append((feature,score))\n",
    "    \n",
    "sorted_by_value = sorted(feature_score, key=lambda pair: -pair[1])\n",
    "sorted_by_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***A vous:*** Quelle est la meilleurs paire de feature? ($4\\heartsuit$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procédure foreward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestFeatureToAdd(model,added_features:list, remaining_features:list):\n",
    "\n",
    "    best_score=float(\"-infinity\")\n",
    "    best_feature=None\n",
    "\n",
    "    for feature in remaining_features:\n",
    "        try_features= added_features + [feature]\n",
    "        score=classification_VC(model,try_features)\n",
    "        \n",
    "        if score>best_score:\n",
    "            best_score=score\n",
    "            best_feature=feature\n",
    "\n",
    "    return best_feature,best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalIncome 1.1935974726176344\n",
      "LoanAmount/TotalIncome 2.0270789329387484\n",
      "Credit_History 2.348201168179076\n",
      "ApplicantIncome 2.5029433311306866\n",
      "Education 2.633522223437903\n",
      "Self_Employed 2.6471633010747015\n",
      "PA_Rural 2.660786128744869\n",
      "Married 2.6738483379106075\n",
      "Dependents_num 2.693243876429304\n",
      "Loan_Amount_Term 2.7033174622289695\n",
      "Graduate&Self_Employed 2.709402929470908\n",
      "PA_Urban 2.7107488781372355\n",
      "Gender 2.7021810605039813\n",
      "TotalIncome_log 2.5847667094582025\n",
      "LoanAmount 2.6096090164258317\n"
     ]
    }
   ],
   "source": [
    "new_ones=list(all_features.copy())\n",
    "old_features=[]\n",
    "\n",
    "while len(new_ones)>0:\n",
    "    best_feature, best_score = bestFeatureToAdd(model_logistic,old_features,new_ones)\n",
    "    print(best_feature, best_score)\n",
    "\n",
    "    old_features.append(best_feature)\n",
    "    new_ones.remove(best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programmer la méthode Backward qui consiste à partir de toutes les features, et à enlever une à une les moins significatives.\n",
    "Pour les deux procédures, choisissez un ensemble de features qui vous semble optimal : attention, il n'y a pas\n",
    " que les scores qui compte, mais aussi votre bon sens. Par exemple, on ne rajoute pas une feature très corrélée pour\n",
    " gagner un score minime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"la méthode de regression logistique de sklearn : Attention, par défaut elle a une pénalisation L2 par défaut.\n",
    "    Travail : Affichez le vecteur model.coef_\n",
    "    Pour voir la fonction loss associée:\n",
    "    http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\"\"\"\n",
    "    model = linear_model.LogisticRegression()\n",
    "\n",
    "\n",
    "    \"\"\"d'autre modèles couramment utilisés en classifications, on ne cherche pas vraiment à comprendre, on en verra\n",
    "     quelque uns en détail. Il faut juste notre qu'ils ont tous la mêmes méthodes fit et decision_function.\n",
    "       Certain modèles (comme le modèle Logistique) donnent des probas de classification, cherchez dans ce cas comment on y a accès.\n",
    "       \"\"\"\n",
    "\n",
    "    #model=linear_model.PassiveAggressiveClassifier()\n",
    "    #model=ensemble.GradientBoostingClassifier()\n",
    "    \"\"\"SVM= Support Vector Model, très simple, on cherche le meilleurs hyperplan qui sépare les données\"\"\"\n",
    "    #model =sk.svm.SVC()\n",
    "    \"\"\"les arbres de regression : on verra cette méthode plus tard\"\"\"\n",
    "    #model =sk.tree.DecisionTreeClassifier()\n",
    "    \"\"\"sans doute une des méthodes les plus à la mode : plein d'arbre aléatoire de regression que l'on fait voter\"\"\"\n",
    "    #model =ensemble.RandomForestClassifier()\n",
    "    \"\"\" les fameux KNN, on verra cela en détail plus tard. \"\"\"\n",
    "    #model =neighbors.KNeighborsClassifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
